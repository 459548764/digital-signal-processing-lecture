{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "# Random Signals\n",
    "\n",
    "*This jupyter notebook is part of a [collection of notebooks](../index.ipynb) on various topics of Digital Signal Processing. Please direct questions and suggestions to [Sascha.Spors@uni-rostock.de](mailto:Sascha.Spors@uni-rostock.de).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "[White noise](https://en.wikipedia.org/wiki/White_noise) is a wide-sense stationary (WSS) random signal with constant power spectral density (PSD)\n",
    "\n",
    "\\begin{equation}\n",
    "\\Phi_{xx}(\\mathrm{e}^{\\,\\mathrm{j}\\, \\Omega}) = N_0\n",
    "\\end{equation}\n",
    "\n",
    "where $N_0$ denotes the power per frequency. White noise draws its name from the analogy to white light. It refers typically to an idealized model of a random signal, e.g. emerging from measurement noise. The auto-correlation function (ACF) of white noise can be derived by inverse discrete-time Fourier transformation (DTFT) of the PSD\n",
    "\n",
    "\\begin{equation}\n",
    "\\varphi_{xx}[\\kappa] = \\mathcal{F}_* \\{ N_0 \\} = N_0 \\cdot \\delta[\\kappa]\n",
    "\\end{equation}\n",
    "\n",
    "This result implies that white noise has to be a zero-mean random process. It can be concluded from the ACF that two neighboring samples $k$ and $k+1$ are uncorrelated. Hence they show no dependencies in the statistical sense. Although this is often assumed, the probability density function (PDF) of white noise is not necessarily given by the normal distribution. In general, it is required to additionally state the amplitude distribution when denoting a signal as white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Toolboxes for numerical mathematics like `Numpy` or `scipy.stats` provide functions to draw uncorrelated random samples with a given amplitude distribution. In order to evaluate this, a function is defined to estimate and plot the PDF and CDF for a given random signal $x[k]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def estimate_plot_pdf_acf(x, nbins=50, acf_range=30):\n",
    "    \n",
    "    # compute and truncate ACF\n",
    "    acf = 1/len(x) * np.correlate(x, x, mode='full')\n",
    "    acf = acf[len(x)-acf_range-1:len(x)+acf_range-1]\n",
    "    kappa = np.arange(-acf_range, acf_range)\n",
    "    \n",
    "    # plot PSD\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.hist(x, nbins, normed=True)\n",
    "    plt.title('Estimated PDF')\n",
    "    plt.xlabel(r'$\\theta$')\n",
    "    plt.ylabel(r'$\\hat{p}_x(\\theta)$')\n",
    "\n",
    "    # plot ACF\n",
    "    plt.subplot(122)\n",
    "    plt.stem(kappa, acf)\n",
    "    plt.title('Estimated ACF')\n",
    "    plt.ylabel(r'$\\hat{\\varphi}_{xx}[\\kappa]$')\n",
    "    plt.xlabel(r'$\\kappa$')\n",
    "    plt.axis([-acf_range, acf_range, 0, 1.1*max(acf)]);\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uniformly distributed white noise**\n",
    "\n",
    "For samples drawn from a zero-mean random process with uniform amplitude distribution, the PDF and ACF are estimated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "estimate_plot_pdf_acf(np.random.uniform(size=10000)-1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets listen to uniformly distributed white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "fs = 44100\n",
    "\n",
    "x = np.random.uniform(size=5*fs)-1/2\n",
    "wavfile.write('uniform_white_noise.wav', fs, np.int16(x*32768))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio src=\"./uniform_white_noise.wav\" controls>Your browser does not support the audio element.</audio>[./uniform_white_noise.wav](./uniform_white_noise.wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Laplace distributed white noise**\n",
    "\n",
    "For samples drawn from a zero-mean random process with with Laplace amplitude distribution, the PDF and ACF are estimated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_plot_pdf_acf(np.random.laplace(size=10000, loc=0, scale=1/np.sqrt(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "* Do both random processes represent white noise?\n",
    "* Estimate the power spectral density $N_0$ of both examples.\n",
    "* How does the ACF change if you lower the length `size` of the random signal. Why?\n",
    "\n",
    "Solution: Both processes represent white noise since the ACF can be approximated reasonably well as Dirac impulse $\\delta[\\kappa]$. The weight of the Dirac impulse is equal to $N_0$. In case of the uniformly distributed white noise $N_0 \\approx \\frac{1}{12}$, in case of the Laplace distributed white noise $N_0 \\approx 1$. Decreasing the length `size` of the signal increases the statistical uncertainties in the estimate of the ACF.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "\n",
    "**Copyright**\n",
    "\n",
    "This notebook is provided as [Open Educational Resource](https://en.wikipedia.org/wiki/Open_educational_resources). Feel free to use the notebook for your own purposes. The text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/), the code of the IPython examples under the [MIT license](https://opensource.org/licenses/MIT). Please attribute the work as follows: *Sascha Spors, Digital Signal Processing - Lecture notes featuring computational examples, 2016-2017*."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
